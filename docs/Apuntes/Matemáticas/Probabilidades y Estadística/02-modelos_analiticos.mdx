import Image from "@site/src/components/Image";
import MDXDetails from "@site/src/components/MDXDetails";

# Modelos analíticos de fenómenos aleatorios

## Variables y distribuciones

### Variables aleatorias

Una **variable aleatoria** es el vehículo matemático para representar un evento en términos analíticos. El valor de una variable aleatoria puede estar definida para un conjunto de posibles valores.

Si $X$ es una variable aleatoria, entonces

$$
X=x, \quad X<x, \quad X>x
$$

representa un evento, donde $(a<X<b)$ es el rango de valores posibles de $X$.
La asignación numérica puede ser natural o artificial.

Formalmente, una variable aleatoria puede ser considerada como una función o regla sobre los eventos del espacio muestral a un sistema numérico (o línea real).

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/va.png"
  alt="Variable aleatoria"
  width="35%"
/>

Así, los eventos $E_1$ y $E_2$ pueden corresponder a

$$
\begin{aligned}
E_1 & =(a<X \leq b) \\
E_2 & =(c<X \leq d) \\
\overline{E_1 \cup E_2} & =(X \leq a) \cup(X>d) \\
E_1 \cap E_2 & =(c<X \leq b)
\end{aligned}
$$

Una variable aleatoria puede ser **discreta** o **continua**.

### Distribuciones de probabilidad

Para los valores o rango de valores que puede tomar una variable aleatoria tienen asociados una probabilidad especifica o medidas de probabilidad. La regla que asigna las medidas de probabilidad se denomina **distribución o ley de probabilidad**.

Si $X$ es variable aleatoria, la distribución de probabilidad puede ser descrita por su función de distribución de probabilidad acumulada denotada por:

$$
F_X(x)=P(X \leq x) \text { para todo } x \in \mathbb{R}
$$

Si $X$ es una variable aleatoria **discreta**, entonces esta función puede ser expresada a través de la función de probabilidad "puntual" denotada por

$$
p_X(x)=P(X=x)
$$

Así,

$$
F_X(x)=\sum_{x_i \leq x} P\left(X=x_i\right)=\sum_{x_i \leq x} p_X\left(x_i\right)
$$

con $x_i \in \Theta_X$ (soporte de $\left.X\right)$.

Ahora, si $X$ es una variable aleatoria **continua**, las probabilidades están asociadas a intervalos de $x$. En este caso se define la función de densidad $f_X(x)$ tal que

$$
P(a<X \leq b)=\int_a^b f_X(x) d x
$$

y

$$
F_X(x)=P(X \leq x)=\int_{-\infty}^x f_X(t) d t
$$

con

$$
f_X(x)=\frac{d}{d x} F_X(x)
$$

Notar que

$$
P(x<X \leq x+d x)=f_X(x) d x
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/caso_discreto_continuo.png"
  alt="Caso discreto y continuo"
  caption="Caso discreto y continuo"
  width="65%"
/>

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/caso_mixto.png"
  alt="Caso mixto"
  caption="Caso mixto"
  width="65%"
/>

### Propiedades

1. $F_X(-\infty)=0$ y $F_X(\infty)=1$.
2. $F_X(x) \geq 0$ para todo valor de $x$ y es no decreciente.
3. $F_X(x)$ es continua por la derecha

Para el caso continuo, la ecuación la podemos escribir como

$$
P(a<X \leq b)=\int_{-\infty}^b f_X(x) d x-\int_{-\infty}^a f_X(x) d x
$$

mientras que en el caso discreto

$$
P(a<X \leq b)=\sum_{x_i \leq b} p_X\left(x_i\right)-\sum_{x_i \leq a} p_X\left(x_i\right)
$$

es decir, para ambos casos

$$
P(a<X \leq b)=F_X(b)-F_X(a)
$$

## Medidas descriptivas de una variable aleatoria

Una variable aleatoria puede ser descrita totalmente por su función de distribución de probabilidad o de densidad, o bien por su función de distribución de probabilidad acumulada. Sin embargo, en la práctica la forma exacta puede no ser totalmente conocida.

En tales casos se requieren ciertas "medidas" para tener una idea de la forma de la distribución.

### Medidas centrales

En el rango de posibles valores de una variable aleatoria, existe un interés natural con respecto a los valores centrales, por ejemplo, el promedio.

Consideremos una variable aleatoria $X$ con soporte $\Theta_X$.
Como cada valor de $\Theta_X$ tiene una medida de probabilidad, el promedio ponderado es de especial interés.

#### Valor esperado

Al promedio ponderado se le llama también **valor medio** o **valor esperado** de la variable aleatoria $X$. Para una variable aleatoria $X$ se define el valor esperado, $\mu_X$, como:

$$
\mu_X=\mathrm{E}(X)= \begin{cases}\displaystyle\sum_{x \in \Theta_X} x \cdot p_X(x), & \text { Caso Discreto } \\[20pt]
\displaystyle\int_{-\infty}^{\infty} x \cdot f_X(x) d x, & \text { Caso Continuo }\end{cases}
$$

Este valor existe siempre y cuando

$$
\sum_{x \in \Theta_X}|x| \cdot p_X(x)<\infty \quad \circ \quad \int_{-\infty}^{\infty}|x| \cdot f_X(x) d x<\infty
$$

#### Moda

Es el valor más frecuente o con mayor probabilidad de ocurrencia. Para los casos discretos y continuos, tenemos que

$$
\begin{aligned}
\text { Caso Discreto: } & \quad \text { Moda }=\max _{x \in \Theta_X} p_X(x) \\
\text { Caso Continuo: } & \quad \text { Moda }=\max _{x \in \Theta_X} f_X(x)
\end{aligned}
$$

#### Mediana

Sea $x_{\text {med }}$ el valor que toma la mediana, entonces

$$
F_X\left(x_{\text {med }}\right)=1 / 2
$$

En resumen, el valor esperado de una variable aleatoria es un valor promedio que puede ser visto como un indicador del valor central de la distribución de probabilidad, por esta razón se considera como un parámetro de localización.

Por otra parte, la mediana y la moda de una distribución también son parámetros de localización que no necesariamente son iguales a la media.

:::tip[Nota]
Cuando la distribución es simétrica, estas tres medidas son parecidas.
:::

### Medidas de posición

#### Percentiles

Si $x_p$ es el valor que toma el percentil $p \times 100 \%$, entonces $F_X\left(x_p\right)=$ $p$.

Algunos casos particulares de percentil son: quintiles, cuartiles, deciles, mediana.

:::tip[Nota]
Los valores para cada tipo de percentil son:

- Quintiles: $p=0.2$
- Cuartiles: $p=0.25$
- Deciles: $p=0.1$
- Mediana: $p=0.5$
  :::

#### Esperanza matemática

La noción del valor esperado como un promedio ponderado puede ser generalizado para funciones de la variable aleatoria $X$.
Dada una función $g(X)$, entonces el valor esperado de esta puede ser obtenido como:

$$
E[g(X)]= \begin{cases}\displaystyle\sum_{x \in \Theta_X} g(x) \cdot p_X(x), & \text { Caso Discreto } \\[20pt]
\displaystyle\int_{-\infty}^{\infty} g(x) \cdot f_X(x) d x, & \text { Caso Continuo }\end{cases}
$$

#### Función generadora de momentos

La función generadora de momentos de una variable aleatoria $X$ se define como

$$
M_X(t)=\mathrm{E}[\exp (t X)]
$$

Esta función puede no estar definida para algunos valores de $t$, pero si existe en un intervalo abierto que contenga al cero, entonces esta función tiene la propiedad de determinar la distribución de probabilidad de $X$.

Cuando esto último ocurra, esta función permite obtener el $r$-ésimo momento de $X$ de la siguiente forma

$$
M^{(r)}(0)=\mathrm{E}\left(X^r\right)
$$

### Medidas de dispersión

Es de interés cuantificar el nivel de dispersión que tienen una variable aleatoria con respecto a un valor de referencia. Por ejemplo, nos podría interesar la distancia esperada de los valores de una variable aleatoria $X$ con respeto al valor esperado $\mu_X$, es decir, $\mathrm{E}\left[\left(X-\mu_X\right)\right]$.

Esta idea de dispersión tiene el problema que siempre da como resultado cero.

#### Varianza

Una alternativa es utilizar la definición de **varianza**, es decir

$$
\begin{aligned}
\sigma_X^2 & =\operatorname{Var}(X)=\mathrm{E}\left[\left(X-\mu_X\right)^2\right] \\
& = \begin{cases}
\displaystyle\sum_{x \in \Theta_X}\left(x-\mu_X\right)^2 \cdot p_X(x), & \text { Caso Discreto } \\[20pt]
\displaystyle\int_{-\infty}^{\infty}\left(x-\mu_X\right)^2 \cdot f_X(x) d x, & \text { Caso Continuo }\end{cases} \\[30pt]
& =\mathrm{E}\left(X^2\right)-\mu_X^2
\end{aligned}
$$

#### Desviación estándar

En términos de dimensionalidad, es conveniente utilizar la **desviación estandar**, es decir,

$$
\sigma_X=\sqrt{\operatorname{Var}(X)}
$$

#### Coeficiente de variación

Ahora, si $\mu_X>0$, una medida adimensional de la variabilidad es el **coeficiente de variación** (c.o.v)

$$
\delta_X=\frac{\sigma_X}{\mu_X}
$$

#### Rango y IQR

Las definiciones para el rango y el rango intercuartílico (IQR) son

$$
\begin{aligned}
\text { Rango } & =\max -\min \\
\mathrm{IQR} & =x_{0.75}-x_{0.25}
\end{aligned}
$$

### Medidas de asimetría

#### Skewness

Se define una medida de asimetría (skewness) corresponde al tercer momento central:

$$
\mathrm{E}\left[\left(X-\mu_X\right)^3\right]= \begin{cases}
\displaystyle\sum_{x_i \in \Theta_X}\left(x_i-\mu_X\right)^3 \cdot p_X\left(x_i\right), & \text { Caso Discreto } \\[20pt]
\displaystyle\int_{-\infty}^{\infty}\left(x-\mu_X\right)^3 \cdot f_X(x) d x, & \text { Caso Continuo }\end{cases}
$$

#### Coeficiente de asimetría

Una medida conveniente es el **coeficiente de asimetría** que se define como:

$$
\theta_X=\frac{E\left[\left(X-\mu_X\right)^3\right]}{\sigma_X^3}
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/skewness.png"
  alt="Skewness"
  caption="Skewness"
  width="55%"
  n
/>

### Medidas de curtosis

#### Curtosis

Finalmente, el cuarto momento central se conoce como la curtosis

$$
\mathrm{E}\left[\left(X-\mu_X\right)^4\right]= \begin{cases}
\displaystyle\sum_{x_i \in \Theta_X}\left(x_i-\mu_X\right)^4 \cdot p_X\left(x_i\right), & \text { Caso Discreto } \\[20pt]
\displaystyle\int_{\infty}^{\infty}\left(x-\mu_X\right)^4 \cdot f_X(x) d x, & \text { Caso Continuo }\end{cases}
$$

que es una medida del "apuntamiento" o "achatamiento" de la distribución de probabilidad o de densidad.

#### Coeficiente de curtosis

Usualmente se prefiere el **coeficiente de curtosis**

$$
K_X=\frac{E\left[\left(X-\mu_X\right)^4\right]}{\sigma_X^4}-3
$$

## Distribuciones de probabilidad

### Normal

La función densidad de una variable aleatoria $X$ con distribución $\operatorname{Normal}(\mu, \sigma)$ es de la forma:

$$
f_X(x)=\frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left\{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right\}, \quad-\infty<x<\infty
$$

con $\mu$ parámetro de localización y $\sigma$ un parámetro de escala o forma tales que:

$$
-\infty<\mu<\infty, \quad 0<\sigma<\infty
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/normal.png"
  alt="Distribución normal"
  caption="Distribución normal"
  width="55%"
/>

Sea $X$ una variable aleatoria $\operatorname{Normal}(\mu, \sigma)$ con función de distribución acumulada $F_X$. Para dos valores dados $a$ y $b$ (con $a<b$) se tiene que:

$$
P(a<X \leq b)=F_X(b)-F_X(a)
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/normal_acumulada.png"
  alt="Distribución normal acumulada"
  caption="Distribución normal acumulada"
  width="55%"
/>

Algunas propiedades:

- $E(X)=\mu$.
- $\operatorname{Var}(X)=\sigma^2$.
- $F_X(x)=\Phi\left(\frac{x-\mu}{\sigma}\right)$.

### Normal estándar

Un caso especial es cuando $\mu=0$ y $\sigma=1$. Este caso es conocido como la distribución normal estándar.

$$
f_X(x)=\frac{1}{\sqrt{2 \pi}} e^{-x^2 / 2}
$$

La ventaja es que función de distribución de probabilidad acumulada se encuentra tabulada, la cual se denota por $\Phi(\cdot)$.

Sea $S$ una variable aleatoria con distribución normal estándar, cuya función de distribución de probabilidad acumulada esta dada por

$$
\Phi(s)=F_S(s)=\int_{-\infty}^s \frac{1}{\sqrt{2 \pi}} e^{-x^2 / 2} d x
$$

Algunas propiedades son:

- $S_p=\Phi^{-1}(p)=-\Phi^{-1}(1-p)$
- $\Phi(-s)=1-\Phi(s)$.

La tabla normal estándar es el resultado de $\Phi\left(S_p\right)=p$ para $S_p \geq 0$:

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/tabla_normal.png"
  alt="Distribución normal estándar"
  caption="Distribución normal estándar"
  width="70%"
/>

### Log-Normal

Se dice que $X$ sigue una ley de probabilidad Log-Normal si su función de densidad esta dada por

$$
f_X(x)=\frac{1}{\sqrt{2 \pi}} \frac{1}{(\zeta x)} \exp \left[-\frac{1}{2}\left(\frac{\ln x-\lambda}{\zeta}\right)^2\right], \quad x \geq 0
$$

Donde,

$$
\lambda=E(\ln X) \quad \text { y } \quad \zeta=\sqrt{\operatorname{Var}(\ln X)}
$$

Algunas propiedades:

- $\ln X \sim \operatorname{Normal}(\lambda, \zeta)$
- $\mu_X=\exp \left(\lambda+\zeta^2 / 2\right)$
- $\text { Mediana }=\exp (\lambda)$
- $\mathrm{E}\left(X^k\right)=\exp (\lambda k) \cdot M_Z(\zeta k), \text { con } Z \sim \operatorname{Normal}(0,1)$
- $\sigma_X^2=\mu_X^2\left(e^{\zeta^2}-1\right)$
- $\zeta=\sqrt{\ln \left(1+\delta_X^2\right)}$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/log_normal.png"
  alt="Distribución log-normal"
  caption="Distribución log-normal"
  width="55%"
/>

:::tip[Nota]
En la distribución log-normal, la relación entre el coeficiente de variación (c.o.v.) $\delta$ y el parámetro $\zeta$ es tal que si los dos son suficientemente pequeños, entonces $\delta \approx \zeta$.
:::

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/relacion_cov_zeta.png"
  alt="Relación entre c.o.v. y zeta"
  caption="Relación entre c.o.v. y parámetro zeta"
  width="65%"
/>

### Binomial y Bernoulli

En las más diversas áreas de la Ingeniería, a menudo los problemas involucran la ocurrencia o recurrencia de un evento, el cual es impredecible, como una secuencia de "experimentos". Por ejemplo:

1. Para un día de lluvia, ¿colapsa o no un sistema de drenaje?
2. Al comprar un producto, ¿éste satisface o no los requerimientos de calidad?
3. Un alumno ¿aprueba o reprueba el curso?

Notar que hay sólo dos resultados posibles para cada "experimento". Las variables descritas pueden ser modeladas por una **secuencia Bernoulli**, la cual se basa en los siguientes supuestos:

1. Cada experimento, tiene una de **dos opciones**: ocurrencia o no ocurrencia del evento.
2. La probabilidad de ocurrencia del evento ("éxito") en cada experimento es **constante** (digamos $p$).
3. Los experimentos son **estadísticamente independientes**.

Dada una secuencia Bernoulli, si $X$ es el número de ocurrencias del evento éxito entre los $n$ experimentos, con probabilidad de ocurrencia igual a $p$, entonces la probabilidad que ocurran exactamente $x$ éxitos en los $n$ experimentos esta representada por la **distribución Binomial**, descrita por

$$
\begin{gathered}
p_X(x)=\binom{n}{x} p^x(1-p)^{n-x}, \quad x=0,1, \ldots, n \\[20pt]
F_X(x)= \begin{cases}
0, & x<0 \\[8pt]
\displaystyle\sum_{k=0}^{[x]}\binom{n}{k} p^k(1-p)^{n-k}, & 0 \leq x<n \\[15pt]
1, & x \geq n\end{cases}
\end{gathered}
$$

El valor esperado y varianza están dados por

$$
E(X)=n p, \quad \operatorname{Var}(X)=n p(1-p)
$$

Por ejemplo, para $\operatorname{Binomial}(n=30, p=1 / 2)$, vemos que

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/binomial.png"
  alt="Distribución binomial"
  caption="Distribución binomial"
  width="60%"
/>

### Geométrica

Dada una secuencia Bernoulli, el número de experimentos hasta la ocurrencia del primer evento exitoso sigue una **distribución geométrica**.

Si el primer éxito ocurre en el $n$-ésimo experimento, los primeros $n-1$ fueron "fracasos". Si $N$ es la variable aleatoria que representa el número de experimentos hasta el primer éxito, entonces:

$$
P(N=n)=p(1-p)^{n-1}, \quad n=1,2, \ldots
$$

La función distribución esta dada por:

$$
F_N(n)=\sum_{k=1}^{[n]} p(1-p)^{k-1}=1-(1-p)^{[n]}
$$

para $n \geq 1$ y cero en otro caso.
Mientras que su valor esperado y varianza son:

$$
E(N)=\frac{1}{p}, \quad \operatorname{Var}(N)=\frac{(1-p)}{p^2}
$$

Por ejemplo, para $\operatorname{Geométrica}(p=1 / 6)$, vemos que

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/geometrica.png"
  alt="Distribución geométrica"
  caption="Distribución geométrica"
  width="60%"
/>

### Binomial negativa

La distribución geométrica permite modelar el numero de experimentos hasta la primera ocurrencia.

El numero de experimentos hasta la $k$-ésima ocurrencia de un éxito es modelada por la distribución binomial negativa.

$$
\begin{gathered}
P\left(T_k=x\right)=\binom{x-1}{k-1} p^k(1-p)^{x-k}, \quad x=k, k+1, k+2, \ldots \\
E\left(T_k\right)=\frac{k}{p}, \quad \operatorname{Var}\left(T_k\right)=\frac{k(1-p)}{p^2}
\end{gathered}
$$

Por ejemplo, para $\operatorname{Bin}-\operatorname{Neg}(k=3, p=1 / 6)$, vemos que

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/binomial_negativa.png"
  alt="Distribución binomial negativa"
  caption="Distribución binomial negativa"
  width="60%"
/>

### Poisson

Muchos problemas físicos de interés para ingenieros y científicos que implican las ocurrencias posibles de eventos en cualquier punto en el tiempo y/o en el espacio. Por ejemplo:

- Los terremotos pueden ocurrir en cualquier momento y en cualquier lugar en una región con actividad sísmica en el mundo.
- Las grietas por fatiga puede producirse en cualquier punto de una soldadura continua.
- Los accidentes de tráfico pueden suceder en cualquier momento en una autopista.

Este problema puede ser modelado como secuencia Bernoulli, dividiendo el tiempo o el espacio en pequeños intervalos "apropiados" tal que solo un evento puede ocurrir o no dentro de cada intervalo (Ensayo Bernoulli).

Sin embargo, si el evento puede ocurrir al azar en cualquier instante de tiempo (o en cualquier punto del espacio), esto puede ocurrir más de una vez en cualquier momento o intervalo de espacio.

En tal caso, las ocurrencias del evento puede ser más apropiado el modelo con un proceso de Poisson o la **secuencia Poisson**.

#### Supuestos

- Un evento puede ocurrir al azar y en cualquier instante de tiempo o en cualquier punto en el espacio.
- La ocurrencia(s) de un evento en un intervalo de tiempo dado (o espacio) es estadísticamente independiente a lo que ocurra en otros intervalos (o espacios) que no se solapen.
- La probabilidad de ocurrencia de un evento en un pequeño intervalo $\Delta t$ es proporcional a $\Delta t$, y puede estar dada por $\nu \Delta t$, donde $\nu$ es la tasa de incidencia media del evento (que se supone constante).
- La probabilidad de dos o más eventos en $\Delta t$ es insignificante.

Bajo los supuestos anteriores, el número de eventos estadísticamente independientes en $t$ (tiempo o espacio) esta regido por la función de probabilidad del modelo Poisson, donde la variable aleatoria $X_t$ : número de eventos en el intervalo de tiempo $(0, t)$.

$$
P\left(X_t=x\right)=\frac{(\nu t)^x e^{-\nu t}}{x !}=\frac{\lambda^x e^{-\lambda}}{x !}, \quad x=0,1,2, \ldots
$$

donde $\nu$ es la tasa de ocurrencia media por unidad de tiempo y $\lambda$ su espe-ranza en $(0, t)$ :

$$
E\left(X_t\right)=\nu t=\lambda
$$

### Exponencial

En un Proceso de Poisson el tiempo transcurrido entre la ocurrencia de eventos puede ser descrito por una **distribución exponencial**.

Si $T_1$ representa al tiempo transcurrido hasta la ocurrencia del primer evento en un Proceso de Poisson, el evento $\left(T_1>t\right)$ implica que en el intervalo $(0, t)$ no ocurren eventos, es decir,

$$
P\left(T_1>t\right)=P\left(X_t=0\right)=\frac{(\nu t)^0 e^{-\nu t}}{0 !}=e^{-\nu t},
$$

con

$$
X_t \sim \operatorname{Poisson}(\nu t)
$$

Por lo tanto la función de distribución de probabilidad acumulada de $T_1$ esta dada por:

$$
F_{T_1}(t)=P\left(T_1 \leq t\right)=1-P\left(T_1>t\right)=1-e^{-\nu t}
$$

Su función densidad se obtiene como sigue:

$$
f_{T_1}(t)=\frac{d}{d t} F_{T_1}(t)=\nu e^{-\nu t}
$$

que corresponde a la función densidad de una variable aleatoria con distribución exponencial.

Esta distribución al igual que la geométrica tiene la propiedad de la **carencia de memoria**, es decir, si $T \sim \operatorname{Exponencial}(\nu)$ entonces se tiene que

$$
P(T>t+s \mid T>s)=P(T>t)
$$

Este resultado, nos permite asumir que **todos los tiempos entre eventos Poisson $(\nu t)$ distribuyen Exponencial $(\nu)$.**

:::tip[Carencia de memoria]
La carencia de memoria es una propiedad que indica que la probabilidad de que un evento ocurra en el futuro no depende de cuánto tiempo ha pasado desde el último evento.
:::

En resumen, una variable aleatoria $X$ con distribución Exponencial de parámetro $\nu>0$, tiene función densidad y de distribución:

$$
f_X(x)=\left\{\begin{array}{ll}
\nu e^{-\nu x}, & x \geq 0 \\
0, & x<0
\end{array} \quad F_X(x)= \begin{cases}0, & x<0 \\
1-e^{-\nu x}, & x \geq 0\end{cases}\right.
$$

Mientras que su valor esperado y varianza son:

$$
\mu_X=\frac{1}{\nu}, \quad \sigma_X^2=\frac{1}{\nu^2}
$$

#### Exponencial trasladada

Una variable aleatoria $X$ con distribución Exponencial de parámetro $\nu>0$, se llama **trasladada** en a si su función densidad y de distribución acumulada son

$$
f_X(x)=\left\{\begin{array}{ll}
\nu e^{-\nu(x-a)}, & x \geq a \\
0, & x<a
\end{array} \quad F_X(x)= \begin{cases}0, & x<a \\
1-e^{-\nu(x-a)}, & x \geq a\end{cases}\right.
$$

Su valor esperado y varianza están dados por

$$
\mu_X=\frac{1}{\nu}+a, \quad \sigma_X^2=\frac{1}{\nu^2}
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/exponencial.png"
  alt="Distribución exponencial"
  caption="Distribución exponencial trasladada"
  width="60%"
/>

### Gamma

Una variable aleatoria $X$ con **distribución Gamma** tiene función densidad

$$
f_X(x)=\frac{\nu^k}{\Gamma(k)} x^{k-1} e^{-\nu x}, \quad x \geq 0
$$

donde $k, \nu$ son parámetros positivos.
La función $\Gamma(\alpha)=\displaystyle\int_0^{\infty} u^{\alpha-1} e^{-u} d u$, la cual tiene las siguientes propiedades:

$$
\begin{aligned}
& \Gamma(\alpha+1)=\alpha \Gamma(\alpha) \\
& \Gamma(n+1)=n ! \text { si } n \in \mathbb{N}_0 \\
& \Gamma(1 / 2)=\sqrt{\pi}
\end{aligned}
$$

#### Relación con distribución Poisson

En un Proceso de Poisson el tiempo transcurrido hasta la ocurrencia del $k$-ésimo evento puede ser descrito por una distribución Gamma.

Si $T_k$ representa al tiempo transcurrido hasta la ocurrencia del $k$ ésimo evento en un Proceso de Poisson, el evento $\left(T_k>t\right)$ implica que en el intervalo $(0, t)$ ocurren a lo más $k-1$ eventos, es decir,

$$
P\left(T_k>t\right)=P\left(X_t \leq k-1\right)=\sum_{x=0}^{k-1} \frac{(\nu t)^x e^{-\nu t}}{x !}
$$

Luego, su función de distribución acumulada esta dada por:

$$
F_{T_k}(t)=1-\sum_{x=0}^{k-1} \frac{(\nu t)^x e^{-\nu t}}{x !}
$$

Se puede demostrar que

$$
f_{T_k}(t)=\frac{d}{d t} F_{T_k}(t)=\frac{\nu^k}{\Gamma(k)} t^{k-1} e^{-\nu t}, \quad t \geq 0
$$

donde su valor esperado y varianza son

$$
\mu_{T_k}=\frac{k}{\nu}, \quad \sigma_{T_k}^2=\frac{k}{\nu^2}
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/gamma.png"
  alt="Distribución gamma"
  width="70%"
/>

#### Gamma trasladada

Una variable aleatoria $X$ tiene distribución Gamma **trasladada** si su función de densidad esta dada por

$$
f_X(x)=\frac{\nu^k}{\Gamma(k)}(x-\gamma)^{k-1} e^{-\nu(x-\gamma)}, \quad x \geq \gamma
$$

donde $k, \mu$ y $\gamma$ son parámetros de la distribución.
Su valor esperado y varianza son:

$$
\mu_X=\frac{k}{\nu}+\gamma, \quad \sigma_X^2=\frac{k}{\nu^2}
$$

### Hipergeométrica

Considere una población finita dividida en dos grupos: $m$ defectuosos y $N-m$ no defectuosos.

Si se toma una muestra aleatoria de tamaño $n$ al azar, la probabilidad que $x$ sean defectuosos esta dada por la función de probabilidad:

$$
p_X(x)=\dfrac{\displaystyle\binom{m}{x}\binom{N-m}{n-x}}{\displaystyle\binom{N}{n}}, \quad \max \{0, n+m-N\} \leq x \leq \min \{n, m\}
$$

En este caso, se dice que:

$$
X \sim \text {Hipergeométrica}(n, N, m)
$$

El cálculo de su valor esperado y varianza requiere un desarrollo bastante complejo cuyo resultado final es el siguiente

$$
\mu_X=n \cdot \frac{m}{N}, \quad \sigma_X^2=\left(\frac{N-n}{N-1}\right) \cdot n \cdot \frac{m}{N} \cdot\left(1-\frac{m}{N}\right)
$$

### Beta

Una variable aleatoria $X$ con **distribución Beta** tiene función densidad

$$
f_X(x)=\frac{1}{B(r, q)} \cdot \frac{(x-a)^{q-1}(b-x)^{r-1}}{(b-a)^{q+r-1}}, \quad a \leq x \leq b
$$

donde $q$ y $r$ son los parámetros de la distribución, y $B(q, r)$ es la función beta dada por

$$
B(q, r)=\int_0^1 x^{q-1}(1-x)^{r-1} d x=\frac{\Gamma(q) \Gamma(r)}{\Gamma(q+r)}
$$

El valor esperado y la varianza son:

$$
\mu_X=a+\frac{q}{(q+r)}(b-a) \quad \sigma_X^2=\frac{q r(b-a)^2}{(q+r)^2(q+r+1)}
$$

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/beta.png"
  alt="Distribución beta"
  width="70%"
/>

### Weibull

Si $T \sim \operatorname{Weibull}(\eta, \beta)$, se tiene que

$$
\begin{aligned}
F_T(t) & =1-\exp \left[-\left(\frac{t}{\eta}\right)^\beta\right] \\
f_T(t) & =\frac{\beta}{\eta}\left(\frac{t}{\eta}\right)^{\beta-1} \exp \left[-\left(\frac{t}{\eta}\right)^\beta\right], \quad t>0
\end{aligned}
$$

Con $\beta>0$, es un parámetro de forma y $\eta>0$, es un parámetro de escala.

Si $t_p$ es el percentil $p \times 100 \%$, entonces

$$
\ln \left(t_p\right)=\ln (\eta)+\frac{1}{\beta} \cdot \Phi_{\text {Weibull }}^{-1}(p), \quad \Phi_{\text {Weibull }}^{-1}(p)=\ln [-\ln (1-p)]
$$

Mientras que su $m$-ésimo momento está dado por

$$
E\left(T^m\right)=\eta^m \Gamma(1+m / \beta)
$$

Luego

$$
\mu_T=\eta \Gamma\left(1+\frac{1}{\beta}\right), \quad \sigma_T^2=\eta^2\left[\Gamma\left(1+\frac{2}{\beta}\right)-\Gamma^2\left(1+\frac{1}{\beta}\right)\right]
$$

### Logística

Si $Y \sim \operatorname{Logística}(\mu, \sigma)$, se tiene que

$$
F_Y(y)=\Phi_{\text {Logística }}\left(\frac{y-\mu}{\sigma}\right) ; \quad f_Y(y)=\frac{1}{\sigma} \phi_{\text {Logística }}\left(\frac{y-\mu}{\sigma}\right), \quad-\infty<y<\infty
$$

donde

$$
\Phi_{\text {Logística }}(z)=\frac{\exp (z)}{[1+\exp (z)]} \quad \text { y } \quad \phi_{\text {Logística }}(z)=\frac{\exp (z)}{[1+\exp (z)]^2}
$$

son la función de probabilidad y de densidad de una Logística Estándar. $\mu \in \mathbb{R}$, es un parámetro de localización y $\sigma>0$, es un parámetro de escala.

Si $y_p$ es el percentil $p \times 100 \%$, entonces

$$
y_p=\mu+\sigma \Phi_{\text {Logística }}^{-1}(p) \text { con } \Phi_{\text {Logística }}^{-1}(p)=\log \left(\frac{p}{1-p}\right)
$$

Su esperanza y varianza están dadas por:

$$
\mu_Y=\mu \quad \qquad \sigma_Y^2=\frac{\sigma^2 \pi^2}{3}
$$

### Log-Logística

Si $T \sim \operatorname{Log-Logistica}$(\mu, \sigma)$, se tiene que

$$
F_T(t)=\Phi_{\text {Logistica }}\left(\frac{\ln (t)-\mu}{\sigma}\right) ; \quad f_T(t)=\frac{1}{\sigma t} \phi_{\text {Logistica }}\left(\frac{\ln (t)-\mu}{\sigma}\right) \quad t>0
$$

$\exp (\mu)$, es un parámetro de escala y $\sigma>0$, es un parámetro de forma.

Si $t_p$ es el percentil $p \times 100 \%$, entonces

$$
\ln \left(t_p\right)=\mu+\sigma \Phi_{\text {Logistica }}^{-1}(p)
$$

#### Momentos

Para un entero $m>0$ se tiene que

$$
E\left(T^m\right)=\exp (m \mu) \Gamma(1+m \sigma) \Gamma(1-m \sigma)
$$

El $m$-ésimo momento no es finito si $m \sigma \geq 1$.
Para $\sigma<1$

$$
\mu_T=\exp (\mu) \Gamma(1+\sigma) \Gamma(1-\sigma)
$$

y para $\sigma<1 / 2$

$$
\sigma_T^2=\exp (2 \mu)\left[\Gamma(1+2 \sigma) \Gamma(1-2 \sigma)-\Gamma^2(1+\sigma) \Gamma^2(1-\sigma)\right]
$$

### t-Student

Un variable aleatoria $T$ tiene **distribución $t$-student** si su función de densidad está dada por:

$$
f_T(t)=\frac{\Gamma[(\nu+1) / 2]}{\sqrt{\pi \nu} \, \Gamma(\nu / 2)}\left(1+\frac{t^2}{\nu}\right)^{-(\nu+1) / 2}, \quad-\infty<t<\infty
$$

El valor esperado y varianza están dados por:

- $\mu_T=0$, para $\nu>1$.
- $\sigma_T^2=\dfrac{\nu}{\nu-2}$, para $\mu>2$.

### Fisher

Si $T \sim \operatorname{Fisher}(\eta, \nu)$, se tiene que

$$
f_T(t)=\dfrac{\Gamma\left(\dfrac{\eta+\nu}{2}\right)}{\Gamma(\eta / 2) \Gamma(\nu / 2)}\left(\dfrac{\eta}{\nu}\right)^{\tfrac{\eta}{2}} \dfrac{t^{\frac{\eta}{2}-1}}{\left(\dfrac{\eta}{\nu} t+1\right)^{\frac{\eta+\nu}{2}}}, \quad t>0
$$

El valor esperado y varianza están dados por:

- $\mu_T=\dfrac{\nu}{\nu-2}$, para $\nu>2$.
- $\sigma_T^2=\dfrac{2 \nu^2(\eta+\nu-2)}{\eta(\nu-2)^2(\nu-4)}$, para $\nu>4$.

### Identificar distribuciones

En general, se pueden seguir los siguientes pasos para identificar la distribución de una variable aleatoria:

- Cumple vs. No cumple $\rightarrow$ Bernoulli.
- Número de "eventos" en periodos $\rightarrow$ Poisson.
- Tiempos de duración o espera $\rightarrow$ Exponencial.
- Suma de eventos individuales $\rightarrow$ Normal.
- Condiciones extremas de un proceso $\rightarrow$ Valor Extremo.

## Múltiples variables aleatorias

Para el par de variables aleatorias $X$ e $Y$ se define la función de distribución de probabilidad acumulada como

$$
F_{X, Y}(x, y)=P(X \leq x, Y \leq y)
$$

La cual satisface la axiomática fundamental de probabilidades:

$$
\begin{aligned}
& F_{X, Y}(-\infty,-\infty)=0 . \\
& F_{X, Y}(-\infty, y)=0 . \\
& F_{X, Y}(x,-\infty)=0 . \\
& F_{X, Y}(x,+\infty)=F_X(x) . \\
& F_{X, Y}(+\infty, y)=F_Y(y) . \\
& F_{X, Y}(+\infty,+\infty)=1 .
\end{aligned}
$$

### Distribución de probabilidad conjunta

Si las variables aleatorias $X$ e $Y$ son **discretas**, la función de distribución de probabilidad conjunta es

$$
p_{X, Y}(x, y)=P(X=x, Y=y)
$$

siendo su función de distribución de probabilidad acumulada igual a

$$
\begin{aligned}
& \quad F_{X, Y}(x, y)=P(X \leq x, Y \leq y)=\sum_{x_i \leq x} \sum_{y_j \leq y} P\left(X=x_i, Y=y_j\right)
\end{aligned}
$$

con $\left(x_i, y_j\right) \in \Theta_{X, Y}$.

Ahora, si las variables aleatorias $X$ e $Y$ son **continuas**, la función de de densidad de probabilidad conjunta se define como:

$$
f_{X, Y}(x, y) d x d y=P(x<X \leq x+d x, y<Y \leq y+d y)
$$

Entonces,

$$
F_{X, Y}(x, y)=\int_{-\infty}^x \int_{-\infty}^y f_{X, Y}(u, v) d v d u
$$

Si las derivadas parciales existen, entonces

$$
f_{X, Y}(x, y)=\frac{\partial^2}{\partial x \partial y} F_{X, Y}(x, y)
$$

También, se puede observar que la siguiente probabilidad puede ser obtenida como

$$
P(a<X \leq b, c<y \leq d)=\int_a^b \int_c^d f_{X, Y}(u, v) d u d v
$$

que representa el volumen bajo la superficie $f_{X, Y}(x, y)$ como se muestra en la figura.

<Image
  src="matematicas/probabilidades_estadistica/modelos_analiticos/superficie.png"
  alt="Volumen bajo la superficie"
  caption="Volumen bajo la superficie"
  width="45%"
/>

### Distribuciones marginales y condicionales

#### Variables discretas

Para variables aleatorias **discretas** $X$ e $Y$, la probabilidad de $(X=x)$ puede depender de los valores que puede tomar $Y$ (viceversa).

Con base a lo visto en probabilidades, se define la **función de distribución de probabilidad condicional** como:

$$
p_{X \mid Y=y}(x)=P(X=x \mid Y=y)=\frac{p_{X, Y}(x, y)}{p_Y(y)}, \quad p_Y(y)>0
$$

De manera similar, se tiene que

$$
p_{Y \mid X=x}(y)=P(Y=y \mid X=x)=\frac{p_{X, Y}(x, y)}{p_X(x)}, \quad p_X(x)>0
$$

La distribución marginal de una variable aleatoria se puede obtener aplicando el teorema de probabilidades totales.

Para determinar la **distribución marginal** de $X, p_X(x)$, tenemos que

$$
\begin{aligned}
p_X(x) & =\sum_{y \in \Theta_Y} p_{X \mid Y=y}(x) \cdot p_Y(y) \\
& =\sum_{y \in \Theta_Y} p_{X, Y}(x, y)
\end{aligned}
$$

De la misma forma se tiene que

$$
p_Y(y)=\sum_{x \in \Theta_X} p_{X, Y}(x, y)
$$

#### Variables continuas

En el caso que ambas sean variables aleatorias **continuas** se define la **función de densidad condicional** de $X$ dado que $Y=y$ como

$$
f_{X \mid Y=y}(x)=\frac{f_{X, Y}(x, y)}{f_Y(y)} \quad f_Y(y)>0
$$

De manera similar se tiene que

$$
f_{Y \mid X=x}(y)=\frac{f_{X, Y}(x, y)}{f_X(x)} \quad f_X(x)>0
$$

Las respectivas **marginales** se obtienen como sigue:

$$
\begin{aligned}
& f_X(x)=\int_{-\infty}^{\infty} f_{X, Y}(x, y) d y \\
& f_Y(y)=\int_{-\infty}^{\infty} f_{X, Y}(x, y) d x
\end{aligned}
$$

#### Caso mixto

En el caso mixto, supongamos $X$ discreta e $Y$ continua, el calculo de las respectivas marginales es

$$
\begin{aligned}
& p_X(x)=\int_{-\infty}^{\infty} p_{X \mid Y=y}(x) \cdot f_Y(y) d y \\
& f_Y(y)=\sum_{x \in \Theta_X} f_{Y \mid X=x}(y) \cdot p_X(x)
\end{aligned}
$$

Si ambas variables aleatorias son independientes, entonces se tiene que

$$
\begin{aligned}
p_{X, Y}(x, y) & =p_X(x) \cdot p_Y(y) \\
f_{X, Y}(x, y) & =f_X(x) \cdot f_Y(y)
\end{aligned}
$$

<MDXDetails>
<summary>Ejemplo: Determinar distribución de una variable</summary>

Tenemos que

$$
X \sim \operatorname{Poisson}(\nu) \text { y } Y \mid X=x \sim \operatorname{Binomial}(x, p)
$$

Luego

$$
\begin{aligned}
p_{X, Y}(x, y) & =p_{Y \mid X=x}(y) \cdot p_X(x) \\
& =\left(\begin{array}{c}
x \\
y
\end{array}\right) p^y(1-p)^{x-y} \cdot \frac{\nu^x e^{-\nu}}{x !}
\end{aligned}
$$

$$
\Theta_{X, Y}=\left\{(x, y) \mid x \in \mathbb{N}_0, y \in \mathbb{N}_0, y \leq x\right\} \text {. }
$$

Por probabilidades totales se tiene que

$$
Y \sim \operatorname{Poisson}(\nu p)
$$

</MDXDetails>

### Covarianza y correlación

Cuando hay dos variables aleatorias $X$ e $Y$, puede haber una relación entre ellas.

En particular, la presencia o ausencia de relación estadística lineal se determina observando el primer momento conjunto de $X$ e $Y$ definido como

$$
E(X Y)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y \cdot f_{X, Y}(x, y) d x d y
$$

Si $X$ e $Y$ son estadísticamente independientes, entonces

$$
E(X Y)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y \cdot f_X(x) \cdot f_Y(y) d x d y=E(X) \cdot E(Y)
$$

La **covarianza** corresponde al segundo momento central y se define como:

$$
\operatorname{Cov}(X, Y)=E\left[\left(X-\mu_X\right)\left(Y-\mu_Y\right)\right]=E(X \cdot Y)-\mu_X \cdot \mu_Y
$$

Si $X$ e $Y$ son estadísticamente independientes, entonces

$$
\operatorname{Cov}(X, Y)=0
$$

:::tip[Nota]
El significado físico de la covarianza se puede inferir de la ecuación:

- Si $\operatorname{Cov}(X, Y)$ es grande y positiva, los valores de $X$ e $Y$ tienden a ser grandes (o pequeños) en relación a sus respectivos medias.
- Si $\operatorname{Cov}(X, Y)$ es grande y negativo, los valores de $X$ tienden a ser grandes con respecto a su media, mientras que los de $Y$ tienden a ser pequeños y viceversa.
- Si $\operatorname{Cov}(X, Y)$ es pequeña o cero, la relación (lineal) entre los valores de $X$ e $Y$ es poca o nula, o bien la relación es **no** lineal.
  :::

La covarianza mide el grado de asociación lineal entre dos variables, pero es preferible su normalización llamada correlación para poder cuantificar la magnitud de la relación.

La **correlación** esta definida como:

$$
\operatorname{Cor}(X, Y)=\frac{\operatorname{Cov}(X, Y)}{\sigma_X \cdot \sigma_Y}
$$

Este coeficiente toma valores en el intervalo $(-1,1)$.

### Esperanza condicional

El valor esperado de una variable aleatoria $Y$ condicionado a la realización $x$ de una variable aleatoria $X$ esta dado por

$$
\mathrm{E}(Y \mid X=x)= \begin{cases}
\displaystyle\sum_{y \in \Theta_{Y \mid X=x}} y \cdot P(Y=y \mid X=x), & \text { caso discreto } \\[25pt]
\displaystyle\int_{y \in \Theta_{Y \mid X=x}} y \cdot f_{Y \mid X=x}(y) d y, & \text { caso continuo }
\end{cases}
$$

Por otra parte, para una función de $Y$, llamemos $h(Y)$, el valor esperado condicional esta dado por

$$
\mathrm{E}[h(Y) \mid X=x]= \begin{cases}
\displaystyle\sum_{y \in \Theta_{Y \mid X=x}} h(y) \cdot P(Y=y \mid X=x), & \text { caso discreto } \\[25pt]
\displaystyle\int_{y \in \Theta_{Y \mid X=x}} h(y) \cdot f_{Y \mid X=x}(y) d y, & \text { caso continuo }\end{cases}
$$

### Teorema de probabilidades totales para el valor esperado

Preparate (mentalmente) para el teorema de probabilidades totales para el valor esperado condicional:

$$
E(X)= \begin{cases}
\displaystyle\sum_{y \in \Theta_Y}\left[\sum_{x \in \Theta_{X \mid Y=y}} x \cdot p_{X \mid Y=y}(x)\right] p_Y(y), & \text { Caso Discreto-Discreto } \\[30pt]
\displaystyle\int_{y \in \Theta_Y}\left[\int_{x \in \Theta_{X \mid Y=y}} x \cdot f_{X \mid Y=y}(x) d x\right] f_Y(y) d y, & \text { Caso Continuo-Continuo } \\[30pt]
\displaystyle\int_{y \in \Theta_Y}\left[\sum_{x \in \Theta_{X \mid Y=y}} x \cdot p_{X \mid Y=y}(x)\right] f_Y(y) d y, & \text { Caso Discreto-Continuo } \\[30pt]
\displaystyle\sum_{y \in \Theta_Y}\left[\int_{x \in \Theta_{X \mid Y=y}} x \cdot f_{X \mid Y=y}(x) d x\right] p_Y(y), & \text { Caso Continuo-Discreto }
\end{cases}
$$

### Teorema de las esperanzas iteradas

El teorema de las esperanzas iteradas es una generalización del teorema de probabilidades totales para el valor esperado condicional.

$$
\begin{aligned}
\mathrm{E}(Y)&=\mathrm{E}[\mathrm{E}(Y \mid X)]\\
\operatorname{Var}(Y)&=\operatorname{Var}[\mathrm{E}(Y \mid X)]+\mathrm{E}[\operatorname{Var}(Y \mid X)]
\end{aligned}
$$

### Mejor predictor

Predecir el valor de una variable aleatoria a partir de otra es un problema común en estadística. Consideremos primero la siguiente situación: *"Predecir la realización de una variable aleatoria $Y$"*. El "mejor" valor $c$ para predecir la realización de $Y$ se puede obtener minimizando el **error cuadrático medio** definido como
$$
\mathrm{ECM}=\mathrm{E}\left[(Y-c)^2\right]
$$

:::tip[Nota]
La constante $c$ que minimiza el $\mathrm{ECM}$ es $\mathrm{E}(Y)$.
:::

Si ahora queremos predecir $Y$ basado en una función de una variable aleatoria $X$, llamemos $h(X)$, que minimice el error cuadrático medio definido como
$$
\begin{aligned}
\mathrm{ECM} & =\mathrm{E}\left\{[Y-h(X)]^2\right\} \\
& =\mathrm{E}\left(\mathrm{E}\left\{[Y-h(X)]^2 \mid X\right\}\right)
\end{aligned}
$$

Entonces, la función $h(X)$ que minimiza ECM necesariamente debe corresponder a $\mathrm{E}(Y \mid X)$.

Por ejemplo, si $X$ e $Y$ distribuyen conjuntamente según una Normal bivariada, entonces el mejor predictor $Y$ basado en $X$ es una función lineal dada por
$$
\mathrm{E}(Y \mid X)=\left(\mu_Y-\mu_X \frac{\rho \sigma_Y}{\sigma_X}\right)+X \frac{\rho \sigma_Y}{\sigma_X}
$$
